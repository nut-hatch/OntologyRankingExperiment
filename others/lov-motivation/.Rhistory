install.packages("slidify")
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
search()
install.packages("KernSmooth")
library(KernSmooth)
?date
a <- date(07022019)
a <- as.Date("07-02-2019")
a
a <- as.Date("2019-02-07")
b <- as.Date("2019-04-05")
b - a
8 * 7
install.packages("scholar")
library(scholar)
ids <- c("B7vSqZsAAAAJ", "qj74uXkAAAAJ")
df <- compare_scholar_careers(ids)
df
get_article_cite_history("XPBWK5cAAAAJ", "HKviVsUxM5wC")
library(scholar)
get_publications(Ieh1dKwAAAAJ)
get_publications("Ieh1dKwAAAAJ")
a <- get_publications("Ieh1dKwAAAAJ")
summary(a)
head(a)
get_article_cite_history("", "b40ySG42IVsJ")
get_article_cite_history("scholar.google.com", "b40ySG42IVsJ")
get_article_cite_history("dLaTXPAAAAAJ", "d1gkVwhDpl0C")
load("~/Documents/Uni.lu/PhD/dev/iot-vocab-selection/IoTVocabSelector/groundtruth/src/main/R/publication-features/ranking-scholardata-session.RData")
View(finalFeatureTable)
?quantile
test <- c(0.06356900996145474,0.07612699954071919,0.06356900996145474,0.11489253328717737,0.07417175996880007,0.04960327958030172,0.06356900996145474)
quantile(test)
?lm
library(swirl)
install_from_swirl(course_name = "Regression Models")
swirl()
plot(child ~ parent, galton)
plot(jitter(child,4) ~ parent,galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
fit <- lm(child ~ parent, galton)
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
rhs - lhs
lhs - rhs
all.equal(lhs,rhs)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
varEst <- var(ols.ic + ols.slope * galton$parent)
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild, sum(varRes, varEst))
all.equal(varChild, varRes+ varEst)
efit <- lm(accel ~ mag+dist, attenu)
mean(efit$residuals)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$distance)
cov(efit$residuals, attenu$dist)
manipulate(myPlot(beta), beta = slider(0.4, .8, step = 0.02))
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .15 * freqData$freq,
xlab = "parent",
ylab = "child"
)
abline(0, beta, lwd = 3)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
manipulate(myPlot(beta), beta = slider(0.4, .8, step = 0.02))
library(manipulate)
install.packages("manipulate")
library(manipulate)
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .15 * freqData$freq,
xlab = "parent",
ylab = "child"
)
abline(0, beta, lwd = 3)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
manipulate(myPlot(beta), beta = slider(0.4, .8, step = 0.02))
swirl()
cor(gpa_nor, gch_nor)
l_nor <- lm(gch_nor ~ gpa_nor)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
lm (x ~ w)
plot(x, w)
plot(w,x)
plot(x, w)
mean(x)
mean(w)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(x~y)
library(datasets)
data(mtcars)
lm(mtcars$)
head(mtcars)
lm(mtcars$wt ~ mtcars$mpg)
lm(mtcars$mpg ~ mtcars$wt)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
mean(x)
8.58-9.31
var(x)
-0.73/0.5642
-0.73/(0.5642^2)
x - mean(x) / var(x)
x
x - mean(x) / (var(x)^2)
x - mean(x) / sqrt(var(x))
x[1] - mean(x) / sqrt(var(x))
(x[1] - mean(x)) / sqrt(var(x))
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(x~y)
mean(x)
var(x)
x_n <- (x - mean(x)) / sqrt(var(x))
y_n <- (y - mean(y)) / sqrt(var(y))
lm(x_n ~ y_n)
x
y
lm(x~y)
lm(y~x)
?formula
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
lm (x~x)
lm(x~x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(x~y)
lm(y~x)
lm1 <- lm(x~y)
lm2 <- lm(y~x)
sd(lm1)
sd(lm1$coefficients)
sd(lm2$coefficients)
lm2$coefficients / lm1$coefficients
2*sd(y)/sd(x)
var(y) / var(x)
cor(y,x)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
mean(x)
lm(x~w)
lm(w~x)
cor(y,x)
cor(w,x)
cor(x,w)
sum(w * x) / sum(w)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
?formula
lm(x~y)
lm(y~x)
swirl()
swirl()
fit <- lm(child ~ parent, galton)
sum(fit$residuals^2/(n-2))
sqrt(sum(fit$residuals^2)/(n-2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu <- mean(galton$child)
sum((galton$child-mu)^2)
sTot <- sum((galton$child-mu)^2)
sRes <- deviance(sTot)
sRes <- deviance(object = galton$child)
sRes <- deviance()
sRes <- deviance(9)
1
sRes <- deviance(fit)
1- (sRes/sTot)
1- sRes/sTot
summary(fit)$r.squared
cor(galton$child,galton$parent)
cor(galton$child,galton$parent)^2
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent -1, galton)
lm(child ~ parent, galton)
lm(child ~ 1, galton)
head(trees)
fit <- lm(Volume ~ Girth + Height + Constant -1, trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ Height + Constant -1,trees2)
lapply(list(fit, fit2), coef)
all <- lm(fertility ~ ., data=swiss)
all <- lm(Fertility ~ ., data=swiss)
summary(all)
lm(Fertility ~ Agriculture, data=swiss)
summary(lm(Fertility ~ Agriculture, data=swiss))
cor(swiss$Examination, swiss$Education)
cor(swiss$Agriculture, swiss$Education)
makelms()
ec <- swiss$Examination + swiss$Catholic
efit <- lm(Fertility ~ . + ec, swiss)
all$coefficients - efit$coefficients
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
lm(y~x)
summary(lm(y~x))
n <- length(y)
beta1 <- cor(y, x) * sd(y) / sd(x)
beta0 <- mean(y) - beta1 * mean(x)
e <- y - beta0 - beta1 * x
summary(fit)$sigma
summary(lm(x~y))$sigma
fit <- lm(y~x)
summary(fit)$sigma
lm(mpg~wt,data= mtcars)
fit2 <- lm(mpg~wt,data= mtcars)
summary(fit2)
?predict
predict(fit2,newdata = data.frame(x = mean(mtcars$mpg)))
head(mtcars)
predict(fit2,newdata = data.frame(x = mean(mtcars$mpg)), interval = ("confidence"))
predict(fit2,newdata = data.frame(mtcars$mpg = mean(mtcars$mpg)), interval = ("confidence"))
y <- mtcars$mpg
x <- mtcars$wt
fit_car <- lm(y ~ x)
predict(fit_car, newdata = data.frame(x = mean(x)), interval = ("confidence"))
?mtcars
y <- mtcars$mpg
x <- mtcars$wt
fit_car <- lm(y ~ x)
predict(fit_car, newdata = data.frame(x = 3), interval = ("confidence"))
y <- mtcars$mpg
x <- mtcars$wt
fit_car <- lm(y ~ x)
predict(fit_car, newdata = data.frame(x = 3), interval = ("prediction"))
fit_car2 <- lm(y ~ I(x/2))
sumCoef2 <- coef(summary(fit_car2))
(sumCoef2[2,1] + c(-1, 1) * qt(.975, df = fit_car2$df) * sumCoef2[2, 2])
library(swirl)
swirl()
6
dim(InsectSprays)
head(InsectSprays,15)
sA
summary(InsectSprays[,2])
sapply(InsectSprays, str)
sapply(InsectSprays, class)
fit <- lm(count ~ spray, data = InsectSprays)
summary(fit)$coef
est<-summary(fit)$coef[,1]
mean(sA)
mean(xB)
mean(sB)
nfit <- lm(count ~ spray-1, data = InsectSprays)
est<-summary(nfit)$coef[,1]
summary(nfit)$coef[,1]
summary(nfit)$coef
spray2 <- relevel(InsectSprays$spray, "C")
fit2 <- lm(count~spray,data = spray2)
1
fit2 <- lm(count ~ spray2, InsectSprays)
summary(fit2)$coef
mean(sC)
fit$coef[2] - fit$coef[3]
(fit$coef[2]-fit$coef[3])/1.6011
dim(hunger)
948
names(hunger)
fit <- lm(Numeric~Year, data=hunger)
summary(fit)$coef
lmF <- lm(Numeric[hunger$Sex=="Female"]~Year[hunger$Sex=="Female"],hunger)
lmM <- lm(Numeric[hunger$Sex=="Male"]~Year[hunger$Sex=="Male"],hunger)
lmBoth <- lm(Numeric, Year + Sex, hunger)
lmBoth <- lm(Numeric~Year + Sex, hunger)
summary(lmBoth)
lmInter <- lm(Numeric~Year+Sex+Sex*Year,hunger)
summary(lmInter)
fit <- lm(y ~ x, out2)
plot(fit, which=1)
fitno <- lm(y ~ x, out2[-1,])
plot(fitno, which=1)
coef(fit) - coef(fitno)
head(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno, out2[1,])
1-resid(fit)[1]/resno
head(hatvalues(fit))
1
sigma <- sqrt(deviance(fit)/df.residual(fit))
1
rstd <- resid(fit)/(sigma * sqrt(1-hatvalues(fit)))
head(cbind(rstd,rstandard(fit)))
plot(fit.which=3)
plot(fit,which=3)
plot(fit, which=2)
1
sigma1 <- sqrt(deviance(fitno)/df.residual(fitno))
1
resid(fit)[1]/(sigma1*sqrt(1-hatvalues(fit)[1]))
head(rstudent(fit))
1
dy <- predict(fitno, out2)-predict(fit, out2)
1
sum(dy^2)/(2*sigma^2)
plot(fit, which=5)
library(datasets)
mtcars
lm(mpg~cyl+wt)
lm(mpg~cyl+wt,mtcars)
summary(lm(mpg~cyl+wt,mtcars))
summary(fit)$coef[3]
mcyl<-relevel(factor(mtcars$cyl),"4")
summary(lm(mpg~mcyl+wt,mtcars))
summary(lm(mpg~mcyl,mtcars))
summary(lm(mpg~mcyl*wt,mtcars))
summary(lm(mpg~mcyl+wt+mycyl*wt,mtcars))
summary(lm(mpg~mcyl+wt+mcyl*wt,mtcars))
mcyl<-factor(mtcars$cyl)
fit1<-lm(mpg~mcyl+wt, data = mtcars)
fit2<-lm(mpg~mcyl+wt+mcyl*wt, data = mtcars)
lrtest(fit1, fit2)
library(lmtest)
install.packages("lmtest")
library(lmtest)
mcyl<-factor(mtcars$cyl)
fit1<-lm(mpg~mcyl+wt, data = mtcars)
fit2<-lm(mpg~mcyl+wt+mcyl*wt, data = mtcars)
lrtest(fit1, fit2)
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
summary(lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars))
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit<-lm(y~x)
max(influence(fit)$hat)
influence(fit)$hat
fit<-lm(y~x)
influence.measures(fit)
library(swilr)
library(swirl)
swirl()
rgp1(9)
rgp1()
rgp2()
head(swiss)
mdl <- lm(Fertility ~ . , data=swiss)
vif(mdl)
mdl <- lm(Fertility ~ . , data=swiss)
mdl2 <- lm(Fertility ~ . -Examination, swiss)
vif(mdl2)
x1c <- sambias()
x1c <- simbias()
apply(x1c, 1, mean)
fit1 <- lm(Fertility~Agriculture, swiss)
fit3 <- lm(Fertility~Examination+Education, swiss)
fit3 <- lm(Fertility~Agriculture+Examination+Education, swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- (deviance(fit1)-deviance(fit3))/2
n/d
pf(n/d, 2, 43, lower.tail=FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
ravenData
1
mdl <- glm(ravenWinNum ~ ravenScore, binomial, ravenData)
predict(mdl,data.frame(ravenScore=c(0, 3, 6)))
lodds <- predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
exp(lodds)/(1+exp(lodds))
summary(mdl)
confint(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0.95, 1)
var(rpois(1000, 50))
head(hits)
class(hits[,'date'])
as.integer(head(hits[,'date']))
mdl <- glm(visits ~ date, poisson, hits)
summary(mdl)
exp(confint(mdl, 'date'))
which.max(hits[,'visits'])
hits[704,]
lambda <- mdl$fitted.values[704]
qpois(.95, lambda)
1
mdl2 <- glm(formula = simplystats ~ date, family = poisson, data = hits, offset = log(visits + 1))
qpois(.95, mdl2$fitted.values[704])
library(MASS)
?shuttle
?glm
data("shuttle")
shuttle <- mutate(shuttle, use = relevel(use, ref="noauto"))
shuttle$use.bin <- as.integer(shuttle$use) - 1
mdl <- glm(use.bin ~ wind - 1, family = "binomial", data = shuttle)
summary(mdl)
library(dplyr)
data("shuttle")
shuttle <- mutate(shuttle, use = relevel(use, ref="noauto"))
shuttle$use.bin <- as.integer(shuttle$use) - 1
mdl <- glm(use.bin ~ wind - 1, family = "binomial", data = shuttle)
summary(mdl)
exp(coef(mdl)[[1]])/exp(coef(mdl)[[2]])
mdl2 <- glm(use.bin ~ wind + magn - 1, family = "binomial", data = shuttle)
summary(mdl2)
exp(coef(mdl2))[[1]]/exp(coef(mdl2))[[2]]
data("InsectSprays")
mdl4 <- glm(count ~ spray -1, family = "poisson", data = InsectSprays)
summary(mdl4)$coef
coefs[[1]]/coefs[[2]]
coefs <- exp(coef(mdl4))
coefs[[1]]/coefs[[2]]
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
install.packages(EvCombR)
install.packages("EvCombR")
library(EvCombR)
?EvCombR
# construct a state space
stateSpace <- c("a", "b", "c")
# construct credal sets with the given state space
c1 <- credal(c(0.1, 0.1, 0.1), c(0.8, 0.8, 0.8), stateSpace)
c2 <- credal(c(0.2, 0.2, 0.2), c(0.9, 0.9, 0.9), stateSpace)
# combine the credal sets
cComb(c1, c2)
# construct mass functions
m1 <- mass(list("a"=0.1, "b"=0.1 , "c"=0.4, "a/b/c"=0.4), stateSpace)
m2 <- mass(list("a"=0.2, "b"=0.2, "c"=0.2, "a/b/c"=0.4), stateSpace)
# combine the mass functin by using Dempster's combination
dComb(m1, m2)
# Yager's combination operator
yComb(m1, m2)
# modified Dempster's combination using uniform prior
mComb(m1, m2)
library(datasets)
head(mtcars)
?mtcars
str(mtcars)
fit1 <- lm(mpg ~ am , data = mtcars)
fit2 <- lm(mpg ~ am + wt, data = mtcars)
fit3 <- lm(mpg ~ am + wt + disp , data = mtcars)
fit4 <- lm(mpg ~ am + wt + disp + cyl, data = mtcars)
fit5 <- lm(mpg ~ am + wt + disp + cyl + hp, data = mtcars)
fit6 <- lm(mpg ~ ., data = mtcars)
anova(fit1, fit2, fit3, fit4, fit5, fit6)
summary(fit6)
?anova
summary(fit1)
summary(fit4)
summary(fit3)
summary(fit2)
summary(fit5)
summary(fit6)
summary(fit4)
summary(fit3)
library(caret)
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("caret")
setwd("~/Documents/Uni.lu/PhD/dev/iot-vocab-selection/OntologyRankingExperiments/others/lov-motivation")
library(jsonlite)
library(tidyverse)
library(tikzDevice)
filename <- "./output/LOVOntologyReuses.tex"
# Read LOV data
vocabCounts <- fromJSON("./input/LOVreusesSPARQLresult.json", flatten = TRUE)
vocabCounts <- vocabCounts %>% select(keyword.value, cntReused.value, cntTotal.value)
vocabCounts$cntReused.value <- as.numeric(vocabCounts$cntReused.value)
vocabCounts$cntTotal.value <- as.numeric(vocabCounts$cntTotal.value)
vocabCounts <- vocabCounts %>%
rowwise() %>%
mutate( mymean = mean(c(cntReused.value,cntTotal.value) )) %>%
arrange(mymean) %>%
mutate(keyword.value=factor(keyword.value, keyword.value)) %>%
mutate("segment"="segment")
vocabCounts
vocabCounts$mymean
vocabCounts %>% mutate(percantageReused=cntReused.value/cntTotal.value)
vocabCounts <- vocabCounts %>% mutate(percantageReused=cntReused.value/cntTotal.value)
vocabCounts <- vocabCounts %>% mutate(percentageReused=cntReused.value/cntTotal.value)
vocabCounts$percentageReused
summary(vocabCounts$percentageReused)
